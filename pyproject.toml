[project]
name = "tritonllm"
description = "Flexible and modular LLM inference for mini-batch"

dependencies = [
  "openai-harmony",
  "tiktoken>=0.9.0",
  "aiohttp>=3.12.14",
  "chz>=0.3.0",
  "docker>=7.1.0",
  "fastapi>=0.116.1",
  "html2text>=2025.4.15",
  "lxml>=4.9.4",
  "pydantic>=2.11.7",
  "structlog>=25.4.0",
  "tenacity>=9.1.2",
  "uvicorn>=0.35.0",
  "requests>=2.31.0",
  "termcolor",
  "torch>=2.7.0",
  "triton==3.4.0",
  "safetensors>=0.5.3",
  "pytest>=8.4.1",
  "modelscope>=1.29.0",
  "numpy>=2.3.2",
]
readme = "README.md"
requires-python = ">=3.11,<3.14"
version = "0.1.0"
authors = [
    { name = "Bob Huang", email = "git@bobhuang.xyz" },
]
license = "MIT"

[project.urls]
repository = "https://github.com/OpenMLIR/TritonLLM"
homepage = "https://tritonllm.top"

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
include-package-data = true

[tool.setuptools.package-data]
"tritonllm" = ["*.txt"]

[tool.setuptools.packages.find]
include = ["tritonllm*"]
